# CONTEXTO Y ESTADO ACTUAL DEL PROYECTO (17/06/2025)

## Estructura de directorios y archivos (ramas y subramas)

### Proyecto principal: botviejo1

- .config/
- .git/
- .gitignore
- .replit
- adaptive_system/
- adaptive_weighting.py
- api_client/
- app.py
- apply_main1_fix.py
- attached_assets/
- automate_ml_workflow.py
- backtesting/
- backtesting.py
- backtest_results/
- backup_assets/
- binance_config.json
- binance_config.py
- binance_data/
    - SOLUSDT_15m_klines.csv
    - SOLUSDT_1h_klines.csv
    - SOLUSDT_1m_klines.csv
    - ... (más archivos de datos históricos y de mercado)
- binance_data_downloader.py
- binance_data_processor.py
- binance_local_trader.py
- binance_real_trading.py
- BINANCE_SETUP_INSTRUCTIONS.md
- binance_simple_downloader.py
- binance_trader_final.py
- binance_trading_bot.py
- bot.log
- bot_20250525.log
- bot_cli.py
- BOT_MANUAL.md
- BOT_STATUS.md
- BOT_STRUCTURE.md
- brain_exports/
- check_balance.py
- check_connection.py
- check_earliest_data.py
- config.env
- config.example.env
- configure_binance_system.py
- copy_trading_modules.py
- core/
- data/
- data_loader.py
- data_management/
- db/
- debug_env.py
- delete_raw_files.bat
- docs/
- download_historical_data.py
- ejemplo_learning_data.json
- export_local_setup.py
- extract_sample.py
- features/
- final_test.py
- fix_all_subscriptions.py
- fix_candles.py
- fix_direct_subscriptions.py
- fix_main1.py
- generated-icon.png
- generate_ml_dataset.py
- generate_target.py
- indicators/
- indicator_weighting.py
- info/
    - 1_BOT_STATUS.md
    - 2_CONTEXT_2025-06-17.md
    - 3_ESTADO_2025-06-17.md
    - 4_ml_target_definition.md
    - 5_README_CONSOLIDADO.md
    - 6_DIRECTRICES_Y_NOTAS_IA.txt
    - 7_ML_WORKFLOW.md
    - 8_PENDIENTES_CONSOLIDADO.txt
    - 9_requirements.txt
    - 10_roadmap_features.md
    - archivados/
        - 2025-06-16.txt
        - ... (más archivos históricos y logs)
    - market_data.db
    - sample_binance_raw_data.txt
- initialize_db.py
- interface/
- learning_data.json
- LOCAL_SETUP_INSTRUCTIONS.md
- log_viewer.py
- main.py
- main1.py
- main_simulacion.py
- market_data.db
- min_max_scaler.joblib
- ml_models/
- models/
- modulo.py
- modulo1.py
- modulo1_copy.py
- modulo2.py
- modulocola.py
- my_trading_modules_20250527_050548/
- my_trading_modules_20250604_045025/
- notifications/
- pair_selector.py
- pattern_recognition.py
- pendientes_modo_real.txt
- prepare_dataset.py
- processed_data/
- process_historical_data.py
- PROJECT_SUMMARY.md
- pyproject.toml
- python
- random_forest_model.joblib
- README.md
- requirements.txt
- review_local_changes.md
- risk_management/
- run_bot.py
- run_ml_backtest.py
- run_scalping_demo.py
- sample_binance_raw_data.csv
- scalping_strategies.py
- setup_binance_credentials.py
- SETUP_COMPLETO_BINANCE.md
- simulate_learning.py
- simulation.py
- sma_signal_generator.py
- SOLUSDT_live_data.csv
- SOLUSDT_ml_dataset.csv
- SOLUSDT_processed_big_dataset.csv
- SOLUSDT_technical_analysis.csv
- SOLUSDT_trading_log.json
- start_bot.py
- static/
- stats_tracker.py
- strategies/
- strategies.py
- templates/
- temp_binance_setup.py
- temp_processed_chunks/
- temp_repo/
- test_binance_system.py
- test_bot.py
- test_db_integration.py
- trading_bot.log
- trading_bot.py
- trading_mode.py
- trading_modules_export/
- train_ml_strategy.py
- train_model.py
- update_schema.py
- utils/
- uv.lock
- verify_price.py
- websocket_client.py
- __pycache__/

---

_Estructura generada automáticamente el 2025-06-17 para contexto y navegación de IAs y humanos._

# CONTEXTO Y ESTADO ACTUAL DEL PROYECTO (17/06/2025)

## Resumen de los últimos cambios y contexto de trabajo
- El proyecto se desarrolla y mantiene principalmente en VS Code, usando integración con GitHub, Google Colab y Google Drive para colaboración, entrenamiento y pruebas multiplataforma.
- El flujo de trabajo incluye edición y ejecución de scripts en local (VS Code), entrenamiento de modelos ML en Colab, y almacenamiento/backup de datos y modelos en Drive.
- Se han realizado múltiples pruebas y refactorizaciones para asegurar rutas multiplataforma y robustas.

## Scripts y archivos clave para Machine Learning y backtesting
- **train_model.py**: Orquesta el pipeline de procesamiento de datos, entrenamiento y guardado de modelos ML (Random Forest). Ahora soporta carga de múltiples archivos históricos fragmentados.
- **binance_data_processor.py**: Procesa los datos brutos, genera features e indicadores, y calcula la variable objetivo (`target`).
- **run_ml_backtest.py**: Ejecuta el backtesting usando el modelo ML entrenado y los datos procesados.
- **binance_data/**: Carpeta donde se almacenan los archivos históricos fragmentados (`SOLUSDT_raw_historical_data_*.csv`).
- **processed_data/**: Carpeta de salida para datasets procesados.
- **ml_models/**: Carpeta de salida para modelos y escaladores entrenados.
- **info/**: Carpeta de logs, documentación y registros de estado.

## Estado actual y problemas detectados
- El pipeline concatena y procesa correctamente los archivos históricos.
- El cálculo del target sigue generando una sola clase, lo que impide el entrenamiento ML (SMOTE y RandomForest requieren al menos dos clases).
- Se han implementado logs y archivos de depuración, pero el problema persiste incluso con umbral 0.0.
- Se han probado diferentes volúmenes de datos (todos los archivos, primeros 3, solo el primero) sin éxito.

## Próximos pasos sugeridos
1. Verificar manualmente la variación de la columna `close` en los datos brutos.
2. Revisar la lógica de cálculo de `future_return` y `target` en `binance_data_processor.py`.
3. Probar con otros símbolos o fuentes de datos para descartar problemas de calidad de datos.
4. Automatizar la generación de fragmentos de depuración para análisis manual.

## Herramientas y plataformas utilizadas
- **VS Code**: Edición, ejecución y depuración de scripts.
- **GitHub**: Control de versiones y colaboración.
- **Google Colab**: Entrenamiento de modelos ML con recursos de GPU.
- **Google Drive**: Backup y sincronización de datos/modelos.

## Contexto para otras IA o programadores
- El proyecto está en fase de integración y depuración del pipeline ML.
- El principal cuello de botella es la generación de la variable objetivo (`target`) y la calidad de los datos históricos.
- Toda la información relevante de cambios, rutas y estado se documenta en la carpeta `info/`.
- El objetivo inmediato es lograr un pipeline de ML funcional de principio a fin, con datos robustos y modelos entrenables.

---

_Archivo generado automáticamente por GitHub Copilot el 17/06/2025 para contexto de IA y futuros programadores._
